{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Question\n",
    "- Which shippers are most/least reliable (arrival time delta between estimated and actual)?\n",
    "\n",
    "#### Sub Questions\n",
    "- Which are the most reliable shippers per country/region/subregion\n",
    "- Which carrier companies are the most reliable?\n",
    "- What, if any, were the reliability changes over the years?\n",
    "    - How did covid affect reliability metrics of shipment times?\n",
    "- Which consignees chose their shippers wisest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Denormalized Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following tables and columns are the ones I primarily require for use case/cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Header\n",
    "| Column | Data Type | Explanation | % non-null in 1st file |\n",
    "| ------ | --------- | ----------- | ---------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| carrier_code | String | Standard Carrier Alpha Code (SCAC) to identify Vessel Operating Common Carriers (VOCC) | 100% |\n",
    "| vessel_country_code | String | Carrier vessel country of origin | 99.99% |\n",
    "| vessel_name | String | Ship's name | 100% |\n",
    "| estimated_arrival_date | String | Time given as estimated shipment arrival | 100% |\n",
    "| actual_arrival_date | String | Real date of arrival | 100% |\n",
    "\n",
    "##### Consignee\n",
    "| Column | Data Type | Explanation | % non-null 1st file |\n",
    "| ------ | --------- | ----------- | ------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| consignee_name | String | Name of company receiving manifest items | 99.99% |\n",
    "| consignee_address_1 | String | Top level address | 99.99% |\n",
    "| consignee_address_2 | String | 2nd level address | 87.80% |\n",
    "| consignee_address_3 | String | 3rd level address | 55.05% |\n",
    "| consignee_address_4  | String | 4th level address | 11.52% |\n",
    "| country_code | String | 2-digit country code | 20.36% |\n",
    "\n",
    "##### shipper\n",
    "| Column | Data Type | Explanation | % non-null 1st file |\n",
    "| ------ | --------- | ----------- | ------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| shipper_party_name | String | Name of company shipping manifest items | 99.99% |\n",
    "| shipper_party_address_1 | String | Top level address | 99.99% |\n",
    "| shipper_party_address_2 | String | 2nd level address | 91.55% |\n",
    "| shipper_party_address_3 | String | 3rd level address | 62.89% |\n",
    "| shipper_party_address_4 | String | 4th level address | 14.36% |\n",
    "| country_code | String | 2-digit country code | 21.21% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Normalized Schema\n",
    "- For answering use case questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD](/Users/jesseputnam/cs-learning/skillstorm/project01/erd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from lib.utils import get_id_nums, clean_row, remove_incorrect_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up countries table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get table of countries with alpha-2 code that includes region from repository\n",
    "    - https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_cols = ['name', 'alpha-2', 'region', 'sub-region']\n",
    "countries = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/country_data.csv', usecols=countries_cols, keep_default_na=False)\n",
    "\n",
    "# Add some extra codes found in data set (outdated -- ex. DD, East German Republic)\n",
    "extra_codes = pd.DataFrame(\n",
    "    {'name': ['Czechia', 'Netherland Antilles', 'Germany', 'European Union'], \n",
    "    'alpha-2': ['XC', 'AN', 'DD', 'EU'], \n",
    "    'region': ['Europe', 'Americas', 'Europe', 'Europe'], \n",
    "    'sub-region': ['Eastern Europe', 'Latin America and the Caribbean', 'Western Europe', 'Western Europe']}\n",
    "    )\n",
    "countries = pd.concat([countries, extra_codes], ignore_index=True, keys=['alpha-2', 'name'])\n",
    "\n",
    "# Change countries index column to be alpha-2 values and rename to id\n",
    "countries.set_index('alpha-2', inplace=True)\n",
    "countries.index.name = 'id'\n",
    "countries.sort_index(inplace=True)\n",
    "\n",
    "# Create country code set with O(1) lookup for table cleaning\n",
    "alpha_2_set = set(countries.index)\n",
    "\n",
    "# Create country name dictionary with O(1) lookup for table cleaning\n",
    "country_dict = {x[1].upper(): x[0] for x in countries.itertuples()}\n",
    "\n",
    "# Add some statistically siginificant outliers, including common 2 common 'typos'\n",
    "country_dict['TAIWAN'] = 'TW'\n",
    "country_dict['SOUTH KOREA'] = 'KR'\n",
    "country_dict['SHANGHAI CN'] = 'CN'\n",
    "country_dict['SHANGHAI'] = 'CN'\n",
    "country_dict['SHANGHAI .'] = 'CN'\n",
    "country_dict['HONG KONG .'] = 'CN'\n",
    "country_dict['TAIPEI .'] = 'TW'\n",
    "country_dict['USA'] = 'US'\n",
    "country_dict['U.S.A.'] = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert altered countries dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_silver_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/silver_layer/countries.csv'\n",
    "countries.to_csv(countries_silver_path, mode='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shipper/Consignee\n",
    "- Both entity tables are handled the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read CSVs to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_0 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2018_part_0.csv')\n",
    "shipper_1 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2018_part_1.csv')\n",
    "shipper_2 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2019_part_0.csv')\n",
    "shipper_3 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2019_part_1.csv')\n",
    "shipper_4 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2020_part_0.csv')\n",
    "shipper_5 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2020_part_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenate shippers DataFrames to single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shippers = pd.concat([shipper_0, shipper_1, shipper_2, shipper_3, shipper_4, shipper_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in name with Unknown\n",
    "shippers['shipper_party_name'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean shipper rows and remove remaining unnecessary columns - (see utils.py for **CLEAN_ROW** function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_clean = shippers.apply(lambda row: clean_row(row, 'shipper_party', alpha_2_set, country_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Result:** out of 40,240,366 values\n",
    "\n",
    "\n",
    "|  | Before Cleaning | After Cleaning |\n",
    "| - | - | - |\n",
    "| country_codes #| 9,911,774 | 13,100,153| \n",
    "| country_codes %| 24.6% | 32.55% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create shipper id column and map IDs by name - (see utils.py for **GET_ID_NUMS** function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_id_dict = get_id_nums(shipper_clean['shipper_party_name'])\n",
    "shipper_clean['shipper_id'] = shipper_clean['shipper_party_name'].map(shipper_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write cleaned data to CSV (time consuming process -- no mistakes)\n",
    "- Cleaned data will be used to create normalized tables for silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_final_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/final/shipper_clean.csv'\n",
    "shipper_clean.to_csv(shipper_final_path, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read header CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_0 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_0.csv')\n",
    "header_1 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_1.csv')\n",
    "header_2 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_2.csv')\n",
    "header_3 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_3.csv')\n",
    "header_4 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_0.csv')\n",
    "header_5 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_1.csv')\n",
    "header_6 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_2.csv')\n",
    "header_7 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_3.csv')\n",
    "header_8 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_0.csv')\n",
    "header_9 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_1.csv')\n",
    "header_10 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concat to a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = pd.concat([header_0, header_1, header_2, header_3, header_4, header_5, header_6, header_7, header_8, header_9, header_10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove erroneous or unknown country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers['vessel_country_code'] = headers['vessel_country_code'].apply(lambda row: remove_incorrect_codes(row, alpha_2_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save cleaned dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_final_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/final/header_clean.csv'\n",
    "headers.to_csv(header_final_path, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junction Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipper_Shipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From **shipper_clean**: identifier, shipper_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consignee_Shipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From **consignee_clean**: identifier, consignee_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver Layer Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove identifier from consignee and shipper, change index to IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change index on header to identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload shipper, header, consignee as as csv for SQL batch loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write SQL DDL table creation file\n",
    "- Write SQL DML insert file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
