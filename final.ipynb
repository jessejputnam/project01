{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Question\n",
    "- Which shippers are most/least reliable (arrival time delta between estimated and actual)?\n",
    "\n",
    "#### Sub Questions\n",
    "- Which are the most reliable shippers per country/region/subregion\n",
    "- Which carrier companies are the most reliable?\n",
    "- What, if any, were the reliability changes over the years?\n",
    "    - How did covid affect reliability metrics of shipment times?\n",
    "- Which consignees chose their shippers wisest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Denormalized Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Header\n",
    "| Column | Data Type | Explanation | % non-null in 1st file |\n",
    "| ------ | --------- | ----------- | ---------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| carrier_code | String | Standard Carrier Alpha Code (SCAC) to identify Vessel Operating Common Carriers (VOCC) | 100% |\n",
    "| vessel_country_code | String | Carrier vessel country of origin | 99.99% |\n",
    "| vessel_name | String | Ship's name | 100% |\n",
    "| estimated_arrival_date | String | Time given as estimated shipment arrival | 100% |\n",
    "| actual_arrival_date | String | Real date of arrival | 100% |\n",
    "\n",
    "##### Consignee\n",
    "| Column | Data Type | Explanation | % non-null 1st file |\n",
    "| ------ | --------- | ----------- | ------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| consignee_name | String | Name of company receiving manifest items | 99.99% |\n",
    "| consignee_address_1 | String | Top level address | 99.99% |\n",
    "| consignee_address_2 | String | 2nd level address | 87.80% |\n",
    "| consignee_address_3 | String | 3rd level address | 55.05% |\n",
    "| consignee_address_4  | String | 4th level address | 11.52% |\n",
    "| country_code | String | 2-digit country code | 20.36% |\n",
    "\n",
    "##### shipper\n",
    "| Column | Data Type | Explanation | % non-null 1st file |\n",
    "| ------ | --------- | ----------- | ------------------- |\n",
    "| identifier | int64 | id of manifest shipment | 100% |\n",
    "| shipper_party_name | String | Name of company shipping manifest items | 99.99% |\n",
    "| shipper_party_address_1 | String | Top level address | 99.99% |\n",
    "| shipper_party_address_2 | String | 2nd level address | 91.55% |\n",
    "| shipper_party_address_3 | String | 3rd level address | 62.89% |\n",
    "| shipper_party_address_4 | String | 4th level address | 14.36% |\n",
    "| country_code | String | 2-digit country code | 21.21% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Normalized Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD](/Users/jesseputnam/cs-learning/skillstorm/project01/erd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from lib.utils import get_id_nums, clean_row, remove_incorrect_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up countries table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get table of countries with alpha-2 code that includes region from repository\n",
    "    - https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_cols = ['name', 'alpha-2', 'region', 'sub-region']\n",
    "countries = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/country_data.csv', usecols=countries_cols, keep_default_na=False)\n",
    "\n",
    "extra_codes = pd.DataFrame(\n",
    "    {'name': ['Czechia', 'Netherland Antilles', 'Germany', 'European Union'], \n",
    "    'alpha-2': ['XC', 'AN', 'DD', 'EU'], \n",
    "    'region': ['Europe', 'Americas', 'Europe', 'Europe'], \n",
    "    'sub-region': ['Eastern Europe', 'Latin America and the Caribbean', 'Western Europe', 'Western Europe']}\n",
    "    )\n",
    "\n",
    "extra_codes\n",
    "countries = pd.concat([countries, extra_codes], ignore_index=True, keys=['alpha-2', 'name'])\n",
    "\n",
    "# Change countries index column to be alpha-2 values and rename to id\n",
    "countries.set_index('alpha-2', inplace=True)\n",
    "countries.index.name = 'id'\n",
    "countries.sort_index(inplace=True)\n",
    "\n",
    "# Create country code set with O(1) lookup for table cleaning\n",
    "alpha_2_set = set(countries.index)\n",
    "\n",
    "# Create country name dictionary with O(1) lookup for table cleaning\n",
    "country_dict = {x[1].upper(): x[0] for x in countries.itertuples()}\n",
    "\n",
    "# Add some statistically siginificant outliers, including common 2 common 'typos'\n",
    "country_dict['TAIWAN'] = 'TW'\n",
    "country_dict['SOUTH KOREA'] = 'KR'\n",
    "country_dict['SHANGHAI CN'] = 'CN'\n",
    "country_dict['SHANGHAI'] = 'CN'\n",
    "country_dict['SHANGHAI .'] = 'CN'\n",
    "country_dict['HONG KONG .'] = 'CN'\n",
    "country_dict['TAIPEI .'] = 'TW'\n",
    "country_dict['USA'] = 'US'\n",
    "country_dict['U.S.A.'] = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read CSVs to DataFrames with only necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_0 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2018_part_0.csv')\n",
    "shipper_1 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2018_part_1.csv')\n",
    "shipper_2 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2019_part_0.csv')\n",
    "shipper_3 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2019_part_1.csv')\n",
    "shipper_4 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2020_part_0.csv')\n",
    "shipper_5 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/shipper_2020_part_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenate shippers DataFrames to single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shippers = pd.concat([shipper_0, shipper_1, shipper_2, shipper_3, shipper_4, shipper_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in name with Unknown\n",
    "shippers['shipper_party_name'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean shipper rows and remove remaining unnecessary columns - (see utils.py for **CLEAN_ROW** function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_clean = shippers.apply(lambda row: clean_row(row, 'shipper_party', alpha_2_set, country_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Result:** out of 40,240,366 values\n",
    "\n",
    "\n",
    "|  | Before Cleaning | After Cleaning |\n",
    "| - | - | - |\n",
    "| country_codes #| 9,911,774 | 13,100,153| \n",
    "| country_codes %| 24.6% | 32.55% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create shipper id column and map IDs by name - (see utils.py for **GET_ID_NUMS** function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_id_dict = get_id_nums(shipper_clean['shipper_party_name'])\n",
    "shipper_clean['shipper_id'] = shipper_clean['shipper_party_name'].map(shipper_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write cleaned data to CSV (time consuming process -- no mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_fail_safe_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/fail_safe_layer/shipper_clean.csv'\n",
    "shipper_clean.to_csv(shipper_fail_safe_path, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consignee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- copy CSVs to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_0 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2018_part_0.csv')\n",
    "consignee_1 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2018_part_1.csv')\n",
    "consignee_2 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2019_part_0.csv')\n",
    "consignee_3 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2019_part_1.csv')\n",
    "consignee_4 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2020_part_0.csv')\n",
    "consignee_5 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/consignee_2020_part_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenate to single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignees = pd.concat([consignee_0, consignee_1, consignee_2, consignee_3, consignee_4, consignee_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill NaN names with N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignees['consignee_name'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean names and country codes, remove unneceessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_clean = consignees.apply(lambda row: clean_row(row, 'consignee', alpha_2_set, country_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map IDs to consignees by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_id_dict = get_id_nums(consignee_clean['consignee_name'])\n",
    "consignee_clean['consignee_id'] = consignee_clean['consignee_name'].map(consignee_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save expensive task to CSV in case of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_fail_safe_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/fail_safe_path/consignee_clean.csv'\n",
    "consignee_clean.to_csv(consignee_fail_safe_path, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read header CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_0 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_0.csv')\n",
    "header_1 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_1.csv')\n",
    "header_2 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_2.csv')\n",
    "header_3 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2018_part_3.csv')\n",
    "header_4 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_0.csv')\n",
    "header_5 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_1.csv')\n",
    "header_6 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_2.csv')\n",
    "header_7 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2019_part_3.csv')\n",
    "header_8 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_0.csv')\n",
    "header_9 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_1.csv')\n",
    "header_10 = pd.read_csv('/Users/jesseputnam/cs-learning/skillstorm/project01/data/bronze_layer/header_2020_part_2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concat to a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = pd.concat([header_0, header_1, header_2, header_3, header_4, header_5, header_6, header_7, header_8, header_9, header_10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_0 = None\n",
    "header_1 = None\n",
    "header_2 = None\n",
    "header_3 = None\n",
    "header_4 = None\n",
    "header_5 = None\n",
    "header_6 = None\n",
    "header_7 = None\n",
    "header_8 = None\n",
    "header_9 = None\n",
    "header_10 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove erroneous or unknown country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers['vessel_country_code'] = headers['vessel_country_code'].apply(lambda row: remove_incorrect_codes(row, alpha_2_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.set_index(['identifier'], inplace=True)\n",
    "headers.index.name = 'shipment_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junction Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_rename = {'identifier': 'shipment_id'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipper_Shipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_shipment = shipper_clean[['identifier', 'shipper_id']].copy()\n",
    "shipper_shipment.index.name = 'shipper_shipment_id'\n",
    "shipper_shipment.rename(columns=identifier_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consignee_Shipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_shipment = consignee_clean[['identifier', 'consignee_id']].copy()\n",
    "consignee_shipment.index.name = 'cosignee_shipment_id'\n",
    "consignee_shipment.rename(columns=identifier_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver Layer Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove identifier from consignee and shipper, drop duplicates on id, change index to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipper_clean.drop(['identifier'], axis=1, inplace=True)\n",
    "shipper_clean.drop_duplicates(subset=['shipper_id'], inplace=True)\n",
    "shipper_clean.set_index(['shipper_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "consignee_clean.drop(['identifier'], axis=1, inplace=True)\n",
    "consignee_clean.drop_duplicates(subset=['consignee_id'], inplace=True)\n",
    "consignee_clean.set_index(['consignee_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change index on header to identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.set_index(['identifier'], inplace=True)\n",
    "headers.index.name = 'shipment_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload shipper, shipment, shipper_shipment, consignee_shipment, consignee as as csv for SQL batch loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/silver_layer/'\n",
    "headers.to_csv(silver_path + 'shipment.csv', mode='w')\n",
    "shipper_clean.to_csv(silver_path + 'shipper.csv', mode='w')\n",
    "consignee_clean.to_csv(silver_path + 'consignee.csv', mode='w')\n",
    "shipper_shipment.to_csv(silver_path + 'shipper_shipment.csv', mode='w')\n",
    "consignee_shipment.to_csv(silver_path + 'consignee_shipment.csv', mode='w')\n",
    "countries.to_csv(silver_path + 'country.csv', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Layer Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prep tables for Gold layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_path = '/Users/jesseputnam/cs-learning/skillstorm/project01/data/gold_layer/'\n",
    "\n",
    "# Choose columns to keep\n",
    "shipper_cols = ['shipper_party_name', 'country_code']\n",
    "consignee_cols = ['consignee_name', 'country_code']\n",
    "header_cols = ['carrier_code', 'vessel_country_code', 'vessel_name', 'estimated_arrival_date','actual_arrival_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload 'denormalized' gold layer tables to folder for virtual mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.to_csv(gold_path + 'country.csv', mode='w')\n",
    "headers[header_cols].to_csv(gold_path + 'shipment.csv', mode='w')\n",
    "shipper_clean[shipper_cols].to_csv(gold_path + 'shipper.csv', mode='w')\n",
    "consignee_clean[consignee_cols].to_csv(gold_path + 'consignee.csv', mode='w')\n",
    "shipper_shipment.to_csv(gold_path + 'shipper_shipment.csv', mode='w')\n",
    "consignee_shipment.to_csv(gold_path + 'consignee_shipment.csv', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = os.getenv('SERVER')\n",
    "username = os.getenv('USER')\n",
    "password = os.getenv('PASSWORD')\n",
    "driver = os.getenv('DRIVER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write SQL table creation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Successfully!\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    conn = pyodbc.connect(driver=driver, server=server, uid=username, pwd=password)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected Successfully!\")\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
